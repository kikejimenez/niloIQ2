{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "{}\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "informal-onion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp experiments.merlion.inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "treated-powell",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "import pandas as pd\n",
    "\n",
    "from merlion.utils.time_series import TimeSeries\n",
    "\n",
    "\n",
    "from national.experiments.merlion import model\n",
    "from national.experiments.merlion import data_splits\n",
    "from national.experiments.merlion import train\n",
    "from national.util.constants import ARIMA_MAX_STEPS, SMES_MAX_STEPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c505816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _forecast(\n",
    "    data: data_splits.Data,\n",
    "    models: List[model.Model],\n",
    "):\n",
    "\n",
    "    if len(data.time_stamps.test) > 0:\n",
    "\n",
    "        for model in models:\n",
    "\n",
    "            #if not model.load_model:\n",
    "            forecast, stderr = model.model.forecast(\n",
    "                time_stamps=data.time_stamps.test,\n",
    "                time_series_prev=data.train,\n",
    "            )\n",
    "\n",
    "            model.forecast.test = forecast\n",
    "            model.stderr.test = stderr\n",
    "\n",
    "    if len(data.time_stamps.val) > 0:\n",
    "\n",
    "        for model in models:\n",
    "            #if not model.load_model:\n",
    "\n",
    "            forecast, stderr = model.model.forecast(\n",
    "                time_stamps=data.time_stamps.val,\n",
    "                time_series_prev=data.train,\n",
    "            )\n",
    "\n",
    "            model.forecast.val = forecast\n",
    "            model.stderr.val = stderr\n",
    "\n",
    "\n",
    "    if len(data.time_stamps.future) > 0:\n",
    "\n",
    "        for model in models:\n",
    "            #if not model.load_model:\n",
    "\n",
    "            forecast, stderr = model.model.forecast(\n",
    "                time_stamps=data.time_stamps.future,\n",
    "                time_series_prev=data.train,\n",
    "            )\n",
    "\n",
    "            model.forecast.future = forecast\n",
    "            model.stderr.future = stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-hawaii",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "class Inference(train.Train):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        kpi: str,\n",
    "        freq: str,\n",
    "        df: pd.DataFrame,\n",
    "        test_frac: float = 0.15,\n",
    "        val_frac: float = 0.15,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            kpi=kpi,\n",
    "            df=df,\n",
    "            freq=freq,\n",
    "            test_frac=test_frac,\n",
    "            val_frac=val_frac,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        self.horizon = [SMES_MAX_STEPS,\n",
    "                        ARIMA_MAX_STEPS][int(ARIMA_MAX_STEPS < SMES_MAX_STEPS)]\n",
    "\n",
    "        sub_test_data = self.data.test[:self.horizon]\n",
    "\n",
    "        self.data.sub_test = sub_test_data\n",
    "\n",
    "        self.data.time_stamps.val = self.data.val.univariates[\n",
    "            self.data.val.names[0]].time_stamps\n",
    "\n",
    "        self.data.time_stamps.test = sub_test_data.univariates[\n",
    "            sub_test_data.names[0]].time_stamps\n",
    "\n",
    "        self.data.time_stamps.train = self.data.train.univariates[\n",
    "            self.data.train.names[0]].time_stamps\n",
    "\n",
    "        self.data.time_stamps.future = self.data.future.univariates[\n",
    "            self.data.future.names[0]].time_stamps\n",
    "\n",
    "        self._models = [\n",
    "            self.models.prophet,\n",
    "            self.models.arima,\n",
    "            self.models.mses,\n",
    "            # self.models.ensemble,\n",
    "            # self.models.partial_ensemble,\n",
    "        ]\n",
    "\n",
    "        if self.include_selector:\n",
    "            self._models = self._models + [self.models.selector]\n",
    "\n",
    "        print('Start forecast')\n",
    "        _forecast(\n",
    "            data=self.data,\n",
    "            models=self._models,\n",
    "        )\n",
    "\n",
    "    def save_models(self):\n",
    "        _model: model.Model\n",
    "        for _model in self._models:\n",
    "            _model.model.save(_model.model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-refund",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arima\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:24:28 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:24:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prophet\n",
      "MSES\n",
      "Start forecast\n"
     ]
    }
   ],
   "source": [
    "from national.data_preprocessing.date_features import Data\n",
    "query = \"product=='Haba' & state=='Sinaloa'\"\n",
    "test_frac = 0.10\n",
    "val_frac = 0.15\n",
    "nal_df = Data().df.query(query)\n",
    "inf = Inference(\n",
    "    df=nal_df,\n",
    "    kpi=\"price\",\n",
    "    freq=\"M\",\n",
    "    load_models=False,\n",
    "    periods=3,\n",
    "    test_frac=test_frac,\n",
    "    val_frac=val_frac,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d685154d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Inference' object has no attribute 'freq'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/niloIQ/nbs/05_Experiments/99_merlion/05_Infer.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://dev-container%2B2f686f6d652f656e72697175652f6e696c6f5f69712f6e696c6f4951/workspaces/niloIQ/nbs/05_Experiments/99_merlion/05_Infer.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m inf\u001b[39m.\u001b[39;49mfreq\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Inference' object has no attribute 'freq'"
     ]
    }
   ],
   "source": [
    "inf.freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcfd6c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            price\n",
       "time             \n",
       "2021-01-31    0.0\n",
       "2021-02-28    0.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf.data.future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4230f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1264896000.0,\n",
       " 1267315200.0,\n",
       " 1269993600.0,\n",
       " 1272585600.0,\n",
       " 1275264000.0,\n",
       " 1277856000.0,\n",
       " 1280534400.0,\n",
       " 1283212800.0,\n",
       " 1285804800.0,\n",
       " 1288483200.0,\n",
       " 1291075200.0,\n",
       " 1293753600.0,\n",
       " 1296432000.0,\n",
       " 1298851200.0,\n",
       " 1301529600.0,\n",
       " 1304121600.0,\n",
       " 1306800000.0,\n",
       " 1309392000.0,\n",
       " 1312070400.0,\n",
       " 1314748800.0,\n",
       " 1317340800.0,\n",
       " 1320019200.0,\n",
       " 1322611200.0,\n",
       " 1325289600.0,\n",
       " 1327968000.0,\n",
       " 1330473600.0,\n",
       " 1333152000.0,\n",
       " 1335744000.0,\n",
       " 1338422400.0,\n",
       " 1341014400.0,\n",
       " 1343692800.0,\n",
       " 1346371200.0,\n",
       " 1348963200.0,\n",
       " 1351641600.0,\n",
       " 1354233600.0,\n",
       " 1356912000.0,\n",
       " 1359590400.0,\n",
       " 1362009600.0,\n",
       " 1364688000.0,\n",
       " 1367280000.0,\n",
       " 1369958400.0,\n",
       " 1372550400.0,\n",
       " 1375228800.0,\n",
       " 1377907200.0,\n",
       " 1380499200.0,\n",
       " 1383177600.0,\n",
       " 1385769600.0,\n",
       " 1388448000.0,\n",
       " 1391126400.0,\n",
       " 1393545600.0,\n",
       " 1396224000.0,\n",
       " 1398816000.0,\n",
       " 1401494400.0,\n",
       " 1404086400.0,\n",
       " 1406764800.0,\n",
       " 1409443200.0,\n",
       " 1412035200.0,\n",
       " 1414713600.0,\n",
       " 1417305600.0,\n",
       " 1419984000.0,\n",
       " 1422662400.0,\n",
       " 1425081600.0,\n",
       " 1427760000.0,\n",
       " 1430352000.0,\n",
       " 1433030400.0,\n",
       " 1435622400.0,\n",
       " 1438300800.0,\n",
       " 1440979200.0,\n",
       " 1443571200.0,\n",
       " 1446249600.0,\n",
       " 1448841600.0,\n",
       " 1451520000.0,\n",
       " 1454198400.0,\n",
       " 1456704000.0,\n",
       " 1459382400.0,\n",
       " 1461974400.0,\n",
       " 1464652800.0,\n",
       " 1467244800.0,\n",
       " 1469923200.0,\n",
       " 1472601600.0,\n",
       " 1475193600.0,\n",
       " 1477872000.0,\n",
       " 1480464000.0,\n",
       " 1483142400.0,\n",
       " 1485820800.0,\n",
       " 1488240000.0,\n",
       " 1490918400.0,\n",
       " 1493510400.0,\n",
       " 1496188800.0,\n",
       " 1498780800.0,\n",
       " 1501459200.0,\n",
       " 1504137600.0,\n",
       " 1506729600.0,\n",
       " 1509408000.0,\n",
       " 1512000000.0,\n",
       " 1514678400.0,\n",
       " 1517356800.0,\n",
       " 1519776000.0,\n",
       " 1522454400.0,\n",
       " 1532995200.0]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf.data.train.univariates['price'].time_stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4262f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                price\n",
       "time                 \n",
       "2021-01-31  44.766750\n",
       "2021-02-28  44.881279"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf.models.arima.forecast.future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e1a0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf.models.arima.forecast.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47623b80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arima\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:20 - cmdstanpy - INFO - Chain [1] start processing\n",
      "15:25:20 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prophet\n",
      "MSES\n",
      "Start forecast\n"
     ]
    }
   ],
   "source": [
    "from national.data_preprocessing.date_features import Data\n",
    "from national.experiments.merlion import inference as merlion_inference\n",
    "query = \"product=='Haba' & state=='Sinaloa'\"\n",
    "test_frac = 0.15\n",
    "val_frac = 0.15\n",
    "nal_df = Data().df.query(query)\n",
    "inf = Inference(\n",
    "    df=nal_df,\n",
    "    kpi=\"price\",\n",
    "    freq=\"4W\",\n",
    "    periods=2,\n",
    "    load_models=False,\n",
    "    test_frac=test_frac,\n",
    "    val_frac=val_frac,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e31bac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arima\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:28 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prophet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15:25:29 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSES\n",
      "Start forecast\n"
     ]
    }
   ],
   "source": [
    "from national.data_preprocessing.date_features import Data\n",
    "query = \"product=='Haba'\"\n",
    "test_frac = 0.15\n",
    "val_frac = 0.15\n",
    "nal_df = Data().df.query(query)\n",
    "inf = Inference(\n",
    "    df=nal_df,\n",
    "    kpi=\"price\",\n",
    "    freq=\"4W\",\n",
    "    load_models=False,\n",
    "    test_frac=test_frac,\n",
    "    val_frac=val_frac,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3352f6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
