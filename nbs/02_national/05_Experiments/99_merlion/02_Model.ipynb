{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "{}\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gothic-album",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp experiments.merlion.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incoming-monroe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from typing import Optional\n",
    "from pathlib import Path\n",
    "from os.path import isdir\n",
    "\n",
    "import merlion.models.forecast\n",
    "from merlion.models.forecast.arima import Arima, ArimaConfig\n",
    "from merlion.models.forecast.prophet import Prophet, ProphetConfig\n",
    "from merlion.models.forecast.smoother import MSES, MSESConfig\n",
    "\n",
    "from merlion.transform.base import Identity\n",
    "from merlion.transform.resample import TemporalResample\n",
    "\n",
    "from merlion.evaluate.forecast import ForecastMetric\n",
    "from merlion.models.ensemble.combine import Mean, ModelSelector\n",
    "from merlion.models.ensemble.forecast import ForecasterEnsemble, ForecasterEnsembleConfig\n",
    "\n",
    "# from national.data_preprocessing.file_system import FileHandler\n",
    "from national.util import constants\n",
    "\n",
    "\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "american-person",
   "metadata": {},
   "source": [
    "Submissions are evaluated on the Root Mean Square Percentage Error (RMSPE). The RMSPE is calculated as\n",
    "\n",
    "\n",
    "\n",
    "$$\\operatorname{RMSPE}=\\sqrt{\\frac{1}{T}\\sum_{t=1}^T\\left(\\frac{ \\hat y_t - y_t}{y_t}\\right)^2}$$\n",
    "\n",
    "where $y_t$ denotes the sales of a single store on a single day and $\\hat y_t$ denotes the corresponding prediction. Any day and store with 0 sales is ignored in scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "published-florence",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "MerlionModel: type = type(merlion.models.forecast)\n",
    "MerlionConfig: type = type(ArimaConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-orange",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "class Evaluation:\n",
    "\n",
    "    def __init_(self):\n",
    "        self.inference: Optional[float] = None\n",
    "        self.train: Optional[float] = None\n",
    "\n",
    "\n",
    "class Results:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.train: Optional[float] = None\n",
    "        self.val: Optional[float] = None\n",
    "        self.test: Optional[float] = None\n",
    "        self.future: Optional[float] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-seating",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "class Model:\n",
    "    \"\"\"All models are initialized using the syntax ModelClass(config),\n",
    "where config is a model-specific configuration object.\n",
    "This is where you specify any algorithm-specific hyperparameters,\n",
    "as well as any data pre-processing transforms.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: MerlionConfig,\n",
    "        model_f: MerlionModel,\n",
    "        load_model: bool,\n",
    "        name: str=None,\n",
    "        **args,\n",
    "    ):\n",
    "        self.config = config\n",
    "        self.model_f = model_f\n",
    "\n",
    "        self.forecast = Results()\n",
    "        self.stderr = Results()\n",
    "        self.evaluation = Evaluation()\n",
    "\n",
    "        _model_dir = \"/workspaces/niloIQ/models/merlion\"\n",
    "\n",
    "        self.model = model_f(\n",
    "            config=config,\n",
    "            **args,\n",
    "        )\n",
    "\n",
    "        self.name = type(self.model).__name__ if name is None else name\n",
    "\n",
    "        self.model_path = Path(_model_dir, self.name)\n",
    "\n",
    "        self.load_model = load_model and isdir(self.model_path)\n",
    "\n",
    "        if self.load_model:\n",
    "            #print(self.name)\n",
    "            self.model = model_f.load(self.model_path, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-pillow",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "\n",
    "class Models:\n",
    "    \"\"\"\n",
    "        ARIMA assumes that input data is sampled at a regular interval,\n",
    "so we set its transform to resample at that interval.\n",
    "We must also specify a maximum prediction horizon.\n",
    "\n",
    "MSES assumes that the input data is sampled at a regular interval,\n",
    "and requires us to specify a maximum prediction horizon. We will\n",
    "also specify its look-back hyperparameter to be 60 here\n",
    "\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        granularity,\n",
    "        load_models: bool = False,\n",
    "    ):\n",
    "\n",
    "        self.granularity = granularity\n",
    "\n",
    "        self.arima = Model(\n",
    "            config=ArimaConfig(\n",
    "                max_forecast_steps=constants.ARIMA_MAX_STEPS,\n",
    "                order=(20, 1, 5),\n",
    "                transform=TemporalResample(granularity=granularity),\n",
    "            ),\n",
    "            model_f=Arima,\n",
    "            load_model=load_models,\n",
    "        )\n",
    "\n",
    "        self.prophet = Model(\n",
    "            config=ProphetConfig(\n",
    "                max_forecast_steps=None,\n",
    "                transform=Identity(),\n",
    "            ),\n",
    "            model_f=Prophet,\n",
    "            load_model=load_models,\n",
    "        )\n",
    "\n",
    "        self.mses = Model(\n",
    "            config=MSESConfig(\n",
    "                max_forecast_steps=constants.SMES_MAX_STEPS,\n",
    "                max_backstep=60,\n",
    "                transform=TemporalResample(granularity=granularity),\n",
    "            ),\n",
    "            model_f=MSES,\n",
    "            load_model=load_models,\n",
    "        )\n",
    "\n",
    "        self.model_names = [\n",
    "            type(self.arima.model).__name__,\n",
    "            type(self.prophet.model).__name__,\n",
    "            type(self.mses).__name__,\n",
    "        ]\n",
    "\n",
    "        # self.ensemble = Model(\n",
    "        #     config=ForecasterEnsembleConfig(\n",
    "        #         combiner=Mean(),\n",
    "        #         model_configs=[\n",
    "        #             (type(self.arima.model).__name__, self.arima.config),\n",
    "        #             (type(self.prophet.model).__name__, self.prophet.config),\n",
    "        #             (type(self.mses.model).__name__, self.mses.config),\n",
    "        #         ]\n",
    "        #     ),\n",
    "        #     model_f=ForecasterEnsemble,\n",
    "        #     load_model=load_models,\n",
    "        # )\n",
    "\n",
    "        # self.selector = Model(\n",
    "        #     config=ForecasterEnsembleConfig(\n",
    "        #         combiner=ModelSelector(metric=ForecastMetric.sMAPE),\n",
    "        #     ),\n",
    "        #     model_f=ForecasterEnsemble,\n",
    "        #     models=[\n",
    "        #         self.arima.model,\n",
    "        #         self.prophet.model,\n",
    "        #         self.mses.model,\n",
    "        #     ],\n",
    "        #     load_model=load_models,\n",
    "        #     name= \"Selector\",\n",
    "        # )\n",
    "\n",
    "        # self.partial_ensemble = Model(\n",
    "        #     config=ForecasterEnsembleConfig(\n",
    "        #         combiner=Mean(),\n",
    "        #         model_configs=[\n",
    "        #             (type(self.arima.model).__name__, self.arima.config),\n",
    "        #             (type(self.prophet.model).__name__, self.prophet.config),\n",
    "        #         ]\n",
    "        #     ),\n",
    "        #     model_f=ForecasterEnsemble,\n",
    "        #     load_model=load_models,\n",
    "        #     name= \"PartialEnsemble\",\n",
    "        # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "from national.experiments.merlion import model as merlion_model\n",
    "models = merlion_model.Models(granularity='W-MON')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-vegetation",
   "metadata": {},
   "source": [
    "##%% export\n",
    "\n",
    "The models considered are ARIMA, Prophet and SMES. Also an ensemble of these three models has been considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apart-afternoon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from national.experiments.merlion import model as merlion_model\n",
    "\n",
    "loaded_models =Models(granularity='W-MON')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.6 ('base')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
